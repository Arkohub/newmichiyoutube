 Conditional probabilities are like ordinary probabilities,  except that they apply to a new situation where some  additional information is available.  For this reason, any concept relevant to probability models  has a counterpart that applies to  conditional probability models.  In this spirit, we can define a notion of conditional  independence, which is nothing but the notion of independence  applied to a conditional model.  Let us be more specific.  Suppose that we have a probability model and two  events, A and B. We are then told that event C occurred,  and we construct a conditional model.  Conditional independence is defined as ordinary  independence but with respect to the conditional  probabilities.  To be more precise, remember that independence is defined  in terms of this relation, that the probability of two  events happening is the product of the probabilities  that one of them is happening times the probability that the  other one is happening.  This is the definition of independence in the original  unconditional model.  Now, in the conditional model we just use the same relation,  but with conditional probabilities instead of  ordinary probabilities.  So this is the definition of conditional independence.  We may now ask, is there a relation between independence  and conditional independence?  Does one imply the other?  Let us look at an example.  Suppose that we have two events and these two events  are independent.  We then condition on another event, C. And suppose that the  picture is like the one shown here.  Are A and B conditionally independent?  Well, in the new universe where C has happened, events A  and B have no intersection.  As we discussed earlier this means that events A and B are  extremely dependent.  Within G, if A occurs, this tells us that B did not occur.  The conclusion from this example is that independence  does not imply conditional independence.  So in this particular example, we saw that the  answer here is no.  Given C, A and B are not independent. 