WEBVTT Kind: captions Language: tr  Aşağıdaki içerik Creative altında sağlandı  Avukat lisansı.  Desteğiniz yardımcı olacaktır MIT OpenCourseWare  yüksek kalite sunmaya devam et ücretsiz eğitim kaynakları.  Bağış yapmak veya ek materyalleri görüntüle  Yüzlerce MIT dersinden, ziyaret MIT OpenCourseWare  ocw.mit.edu adresinde  ERIC GRIMSON: Tamam.  Tekrar hoşgeldiniz.  Bilirsin işte bu süre ne zaman  hepimiz bunu yapıyoruz.  Bakalım bir kaç tane alabilir miyim sadece size not vererek gülümser  o iki hafta bugün son sınıftır.  En azından bir değer olmalı Biraz gülümse, değil mi?  Profesör Guttag gülümsüyor.  Bu fikri sever.  Neredeyse oradasın.  Ne yapıyoruz son dersler?  Hakkında konuşuyoruz doğrusal regresyon.  Ve sadece istiyorum sana bunu hatırlatmak  benim fikrimdi bazı deneysel veriler.  Koyduğum bir bahar davası ölçüye göre farklı ağırlıklar  değiştirmeler.  Ve regresyon veriyordu bize bir model çıkarmanın bir yolu  bu verilere uyacak şekilde.  Ve bazı durumlarda kolaydı.  Örneğin biliyorduk doğrusal bir model olacak.  En iyi çizgiyi bulduk bu veriye uyuyordu.  Bazı durumlarda doğrulama kullanabiliriz  aslında araştırmamıza izin vermek en iyi modeli bulmak için  uygun olup olmadığını doğrusal, ikinci dereceden bir kübik,  bazı yüksek dereceli bir şey.  Yani biz onu kullanacağız Bir model hakkında bir şeyler çıkarmak.  Bu güzel bir segue içine sonraki üç konu  Son büyük dersler sınıfın konusu,  bu makine öğrenmesidir.  Ve ben tartışacağım, yapabilirsin Bunun gerçekten olup olmadığını tartışma  öğrenme örneği.  Ama birçoğu var bizler  ne zaman konuşmak istiyoruz Makine öğrenmesi hakkında konuşun.  Yani her zamanki gibi bir okuma ödevi.  Kitabın 22. Bölümü Bu konuda iyi bir başlangıç.  ve takip edecek diğer parçaları ile.  Ve başlamak istiyorum temelde ana hatlarıyla  ne yapacağız.  Ve ben gidiyorum diyerek başlayın,  bildiğinden emin olduğum gibi bu çok büyük bir konudur.  Sadece beş tane listeledim 6. dersteki konular  tüm odaklanmak makine öğrenme.  Ve bu değil diğer konuları dahil et  öğrenme nerede merkezi bir bölüm.  Doğal dil işleme, hesaplamalı biyoloji,  Bilgisayar görüşü robotiklerin hepsi bugün  ağırlıklı olarak makine öğrenmesi üzerine.  Ve bunları göreceksiniz Bu konular da.  Yani gitmeyeceğiz beş konu sıkıştır  üç derste.  Ama ne yapacağız size tanıtım yapmak.  Konuşarak başlayacağız temel kavramlar hakkında  Makine öğrenmesi.  Örnek alma fikri ve özellikler hakkında nasıl konuşursun  bunları temsil eden örnekler, nasıl  mesafeleri ölçtün onların arasında,  ve kavramı kullanın denemek için mesafe  ve grup benzer bir şey olarak birlikte işler  makine öğrenmesi.  Ve biz gidiyoruz sonuç olarak bak  iki farklı standart öğrenme yapmanın yolları.  Bir, biz ararız sınıflandırma yöntemleri  Örnek biz görecek, orada  denilen bir şey "en yakın komşu k"  ve ikinci sınıf, kümeleme yöntemleri denir.  Sınıflandırma çalışmaları iyi ne zaman bende  etiketli verileri çağırırız.  Etiketleri biliyorum örnekler ve ben  bunu kullanacak sınıfları dene  öğrenebileceğimi ve kümeleme iyi çalışıyor,  etiketli verilerim olmadığında.  Ve ne olduğunu göreceğiz birkaç dakika içinde demektir.  Ama biz vereceğiz bu konuda erken bir görüş.  Profesör Guttag sürece fikrini değiştirir,  muhtemelen gitmeyeceğiz sana gerçekten akımı göster  gelişmiş makine öğrenme yöntemleri  evrişimli sinir gibi ağlar veya derin öğrenme  okuyacağın şeyler haberlerde hakkında.  Ama sen gidiyorsun ne olduğunu anlamak  bunların arkasında, bakarak ne yaptığımız zaman  öğrenme algoritmaları hakkında konuşur.  Yapmadan önce istiyorum sana işaret etmek  Bunun ne kadar yaygın olduğu.  Ve itiraf edeceğim gri saçımla  AI’da çalışmaya başladım. 1975'te makine öğrenmesiyken  yapılacak oldukça basit bir şey.  Ve oldu izlemek büyüleyici  40 yılda değişim.  Ve eğer düşünürsen, sadece nerede gördüğünü düşün.  AlphaGo, makine öğrenmeye dayalı Google'dan yenen sistem  dünya standartlarında seviye Go oyuncu.  Satranç zaten fethedildi bir süre bilgisayarlar tarafından.  Git şimdi bilgisayarlara ait.  En iyi Go oyuncuları dünya bilgisayardır.  Eminim çoğundan Netflix'i kullanıyorsun.  Herhangi bir tavsiye sistem, Netflix,  Amazon, favorini seç, kullanır bir makine öğrenme algoritması  senin için bir şeyler önermek için.  Ve aslında, muhtemelen Google’da gördüm, değil mi?  Açılan reklamlar Google’da  bir makineden geliyor öğrenme algoritması bu  tercihlerine bakmak.  Korkunç düşünce  İlaç keşfi, karakter Tanıma-- postane  karakter tanıma yapar el yazısı karakterleri kullanarak  bir makine öğrenme algoritması ve bir bilgisayarlı görü sistemi  arkasında.  Muhtemelen yapmazsın bu şirketi biliyorum.  Bu aslında bir MIT İki Sigma denilen spin-off,  New York'ta bir hedge fonudur.  AI ve yoğun olarak kullanıyorlar makine öğrenmesi teknikleri.  Ve iki yıl önce, onların fon% 56 getiri sağladı.  Keşke fona yatırım yapsaydım.  Bende çeşit yok İhtiyacınız olan milyonlarca  ama bu etkileyici bir geri dönüş.  % 56 getiri bir yılda para.  Geçen sene yapmadılar Oldukça iyi  ama son derece iyi kullanıyorlar makine öğrenmesi teknikleri.  Siri.  Başka bir büyük MIT Mobileye adlı şirket  bilgisayar vizyonu mu ağır makineli sistemler  öğrenme bileşeni yardımcı sürüşlerde kullanılır  ve kullanılacak tamamen özerk sürüş.  Gibi şeyler yapacak frenlerine bas  eğer çok hızlı kapanıyorsan önünüzdeki arabada,  hangisi olacak benim için gerçekten kötü ol  çünkü ben sürüyorum Bostonlı gibi.  Ve olurdu sürekli tekmelemek.  Yüz tanıma.  Facebook bunu kullanıyor diğer birçok sistem  ikisini de tespit etmek ve yüzleri tanımak.  IBM Watson, kanser teşhisi.  Bunların hepsi sadece makine örnekleri  her yerde kullanıldığını öğrenme.  Ve gerçekten öyle.  Sadece dokuz tane seçtim.  Peki bu nedir?  Bir yapacağım iğrenç ifade.  Şimdi buna alışkınsın.  İddia edeceğim yapabileceğini  hemen hemen her bilgisayarın program bir şeyler öğrenir.  Fakat öğrenme seviyesi Gerçekten çok değişir.  Öyleyse geri dönmeyi düşünüyorsan 60001’deki ilk ders,  Newton'un metodunu gösterdik kare kökleri hesaplamak için.  Ve tartışabilirsin. uzatmak zorunda kalacaksın  ama tartışabilirsin bu yöntemin öğrendiğini  nasıl yapılır hakkında karekök hesaplar.  Aslında genelleştirebilirsin Herhangi bir emir gücünün köklerine.  Ama gerçekten öğrenmedi.  Gerçekten programlamak zorunda kaldım.  Tamam.  Geçen haftayı düşünün. Doğrusal regresyon hakkında konuştu.  Şimdi hissetmeye başlıyor biraz daha  Bir öğrenme algoritması gibi.  Çünkü ne yaptık?  Sana bir set verdik Veri noktalarının  kütle yer değiştirme veri noktaları.  Ve sonra size nasıl gösterdik bilgisayar aslında olabilir  bu veri noktasına bir eğri sığdırır.  Ve bir anlamda, bu veri için bir model öğrenme  o zaman kullanabileceğini davranışını tahmin etmek için.  Diğer durumlarda  Ve bu oluyor neye daha yakın  ne zaman isteriz bir makine düşün  öğrenme algoritması.  Bunu programlamak isteriz Deneyimden öğrenebilir,  yapabileceği bir şey yeni gerçekleri ortaya çıkarmak için kullanın.  Şimdi bir sorun oldu Çok uzun süre AI.  Ve bu teklifi seviyorum.  Bir beyefendiden Sanat Samuel adlı.  1959 alıntı İçinde söylediği  onun tanımı makine öğrenme  çalışma alanı bu bilgisayarlar verir  olmadan öğrenme yeteneği açıkça programlanmış olmak.  Ve bence çok insanlar tartışacak  ilk böyle bir programı yazdı.  Deneyimden öğrendi.  Bu durumda, dama oynadı.  Bir çeşit size nasıl gösterir alan ilerledi.  Ama dama ile başladık. satranç yapmalıyız, şimdi gidiyoruz.  Ama dama oynadı.  Ulusal seviyeyi geçti oyuncular, en önemlisi,  öğrendi yöntemlerini geliştirmek  oyunlarda nasıl yaptığını izleyerek ve sonra bir şey çıkarsama  ne düşündüğünü değiştirmek Bunun yaptığı gibi.  Samuel bir demet yaptı başka şeylerden.  Sadece bir tanesini vurguladım.  Bir görebilirsiniz dersi takip et,  O ne denir icat etti Alfa-Beta Budama, hangi  gerçekten yararlı arama yapmak için teknik.  Fakat fikir şu ki, nasıl olabilir bilgisayarın öğrenmesini sağladık  olmadan açıkça programlanmış mı?  Ve bir yolu bunun hakkında düşün  farkı düşünmek normalde nasıl olurduk  program ve ne yapardık Bir makine öğrenmesinden olduğu gibi  algoritması.  Normal programlama, ben ikna olmadığını biliyorum  böyle bir şey var normal programlama olarak  ama eğer düşünüyorsanız geleneksel programlama,  süreç nedir  Bir program yazıyorum Bilgisayara giriş yapıyorum  böylece yapabilir veri almak ve üretmek  bazı uygun çıktılar.  Ve karekök bulucu gerçekten orada oturuyor, değil mi?  Newton kullanmak için kod yazdım karekök bulma yöntemi,  ve sonra bana verdi Herhangi bir sayının verilmesi,  Sana karekök vereceğim.  Ama düşünürsen geçen sefer ne yaptık  biraz farklıydı.  Ve aslında, bir makinede öğrenme yaklaşımı  fikir şu ki ben gidiyorum bilgisayar çıktısını vermek.  Ben ona örnekler vereceğim programın ne yapmasını istiyorum  veri üzerindeki etiketler, karakterizasyonu  farklı şeyler sınıfları.  Ve ne istiyorum bilgisayar yapmak  , bu karakterizasyonu verilen çıktı ve veri  O makineyi istedim öğrenme algoritması  aslında üretmek benim için bir program  Yapabileceğim bir program sonra çıkarsama için kullanın  şeyler hakkında yeni bilgiler.  Ve eğer yaratırsan, gibi, gerçekten güzel bir döngü  nerede alabilirim makine öğrenme algoritması  programı öğren hangisini daha sonra kullanabilirim  başka bir sorunu çözmek için.  Bu gerçekten olurdu Yapabilirsek harika.  Ve önerdiğim gibi, bu eğri uydurma algoritması  bunun basit bir versiyonudur.  İçin bir model öğrendi o zaman yapabildiğim veriler  diğerlerini etiketlemek için kullanın veri örnekleri  veya ne göreceğimi tahmin et yay yer değiştirme şartları  kitleleri değiştirdiğim gibi.  Demek bu tür bir fikir Keşfetmeye gidiyoruz.  Öğrenmek istiyorsak şeyler, biz de yapabiliriz  sor, peki nasıl öğrenirsin?  Bir bilgisayar nasıl öğrenmeli?  Bir insan olarak senin için orada birkaç olasılık var.  Bu çok sıkıcı.  Bu eski stil Bunu yapmanın yolu değil mi?  Gerçekleri ezberle.  Sizin kadar gerçekleri ezberlemek sana sorabiliriz ve umarız  final sınavında bu gerçeklerin örnekleri  başkalarına karşı ezberlemediğin gerçekler.  Bu, eğer böyle düşünüyorsan ilk derse geri dön  bildirim örneği bilgi, doğruluk beyanları.  Mümkün olduğu kadar çok ezberleyin.  Wikipedia'da var arka cebinde  Öğrenmenin daha iyi bir yolu çıkarım yapabilmek, sonuç çıkarmak  eskiden yeni bilgiler.  Ve eğer düşünüyorsan bu konuda, bu  neye yaklaşıyoruz zorunlu bilgi denir  yeni şeyler çıkarmanın yolları.  Şimdi, ilkinde davalar inşa ettik  Bunu biz yazdığımızda karekök yapmak için program.  Ama ne istiyoruz bir öğrenme algoritması  çok daha fazla sahip olmak bu genelleme fikri.  Biz ilgileniyoruz yeteneklerimizi genişletmek  program yazabilmek yararlı bilgi çıkarımı  örtük verilerdeki kalıplar.  Yani bir şey değil açıkça inşa  Bunun karşılaştırması gibi ağırlıklar ve yer değiştirmeler,  ama aslında örtük verilerdeki kalıplar,  ve algoritma şekline sahip bu kalıpların ne olduğunu  ve bunları kullan size bir program oluşturmak  yeni çıkarım için kullanabilirsiniz nesneler hakkında veri  dize hakkında ne olursa olsun  yapmaya çalışıyorsun.  TAMAM.  Öyleyse fikir o zaman, temel paradigma  gidiyoruz görmek için biz mi  verecek biraz eğitim sistemi  veri, bazı gözlemler.  Bunu geçen sefer yaptık. Sadece bahar yer değiştirmeleri.  Biz o zaman gidiyoruz dene ve bir yolunu dene  anlamak için nasıl kod yazarız, nasıl yaparız  program yaz, sistem bu bir şey çıkartacak  Bu süreç hakkında veri oluşturuldu?  Ve sonra öyle olmak istiyoruz  Bunu yapmak için kullanmak mümkün şeyler hakkında tahminler  daha önce görmedik.  Bu yüzden tekrar istiyorum eve bu noktaya sür.  Eğer düşünürsen, bahar örneği bu modele uyar.  Sana bir dizi verdim veri, mekansal sapmalar  kütle yer değiştirmelerine göre.  Farklı kitleler için nasıl bahar ne kadar ileri gitti?  Sonra bir şey çıkardım temel süreç hakkında.  İlk durumda ben Doğrusal olduğunu biliyorum.  ama ne olduğunu çözmeme izin ver gerçek lineer denklem.  Bahar sabiti ne ile ilişkili?  Ve bu sonuca dayanarak, Bir kod parçam var  Tahmin etmek için kullanabilirim yeni yer değiştirmeler.  Yani hepsine sahip elemanlar, eğitim verileri,  bir çıkarım motoru, ve sonra yetenek  bunu yapmak için kullanmak Yeni tahminler.  Ama bu çok basit tür öğrenme ortamı.  Yani daha yaygın biri ben  olarak kullanacak bir örnek  sana verdiğimde bir dizi örnek,  bu örnekler bazı bunlarla ilgili veriler,  bazı özellikler ve bazı etiketler.  Her örnek için Bunu söyleyebilirim  özel bir şey.  Bu diğeri başka bir şey.  Ve ne istiyorum çözmek  çıkarsama yapmak nasıl yeni şeyler etiketlemek.  Yani sadece bu değil, ne kütlenin yer değiştirmesi,  bu aslında bir etiket.  Ve birini kullanacağım en sevdiğim örnekleri  Ben büyük bir yeni İngiltere Patriots hayranı,  değilseniz, özür dilerim.  Ama kullanacağım Futbol oyuncuları  Bu yüzden göstereceğim bir saniye sonra  Sana bir dizi vereceğim Futbolcu örnekleri  Etiket oynadıkları pozisyonda.  Ve veriler, tamam birçok şey olabilir.  Kullanacağız yükseklik ve ağırlık.  Ama ne istiyoruz yapmak sonra görmek  nasıl buluruz nitelendirmenin bir yolu  örtük kalıbı nasıl ağırlık ve boy öngörüyor mu  pozisyon türü Bu oyuncu oynayabilir.  Ve sonra gel bir algoritma ile  Bu tahmin edecek yeni oyuncuların pozisyonu.  Taslağı yapacağız sonraki yıl için.  Nerede oynamasını istiyoruz?  Bu paradigmadır.  Potansiyel gözlemler seti etiketli, potansiyel olarak değil.  Nasıl yapacağımızı düşün Bir model bulmak için çıkarım.  Ve sonra bunu nasıl kullanırız? Tahmin yapma modeli.  Ne gidiyoruz görmek için ve biz  çoklu görecek bugün örnekler  bu mu öğrenme yapılabilir  iki çok geniş yollardan birinde.  İlki denir denetimli öğrenme  Ve bu durumda, her yeni örnek için  Sana bir parçası olarak veriyorum Eğitim verilerinin  Üzerinde bir etiket var.  Ne olduğunu biliyorum.  Ve ne gidiyorum yapmak nasıl yapılır  bir kuralı mı bulabilirim ilişkili etiketi tahmin et  görünmeyen girdi tabanlı bu örnekler üzerinde.  Denetlenir çünkü ben etiketlemenin ne olduğunu biliyorum.  İkinci tür, eğer bu denetlenir,  bariz diğeri denetimsiz denir.  Bu durumda, ben sadece gidiyorum size birkaç örnek vereceğim.  Ama etiketleri bilmiyorum onlarla ilişkili.  Ben sadece gidiyorum dene ve ne bul  doğal yollardır bu örnekleri gruplandırmak  farklı modellerde birlikte.  Ve bazı durumlarda, bilebilirim Kaç tane model var?  Bazı durumlarda sadece ne olduğunu söylemek istiyorum  bulabildiğim en iyi gruplama.  TAMAM.  Bugün ne yapacağım çok fazla kod değil.  Bunun için alkış bekliyordum. John, ama onları anlamadım.  Çok fazla kod yok.  Ne yapacağım temelde size göstermek  arkasındaki sezgiler bu öğrenmeyi yapıyorum.  Ve ben ile başlayacağım New England Patriots örneği.  Yani burada bazı veri noktaları Mevcut Patriots oyuncuları hakkında.  Ve bende iki tane var pozisyon çeşitleri.  Alıcılarım var ve bende ketenler var.  Ve her biri sadece etiketli adı, inç cinsinden yüksekliği,  ve kilo olarak kilo.  TAMAM?  Her biri beşi.  Bunları bir arsa üzerinde iki boyutlu arsa,  Ben böyle alayım.  TAMAM?  Önemli değil.  Ne yapmaya çalışıyorum?  Öğrenmeye çalışıyorum onların özellikleri  Bu iki ayırt birbirinden sınıflar?  Ve etiketlenmemiş dava, sahip olduğum her şey  sadece bir dizi örnek.  Peki ne istiyorum ne karar ver  iki oyuncuyu benzer yapar görme amacı ile,  bunu ayırabilir miyim iki veya daha fazlasına dağıtım  doğal gruplar  Benzer bir mesafe ölçüsüdür.  Nasıl alırım diyor değerleri olan iki örnek  veya özellikler ilişkili ve biz  nasıl karar vereceğim uzaklarda mı?  Ve etiketlenmemiş durumda, Bunu yapmanın basit bir yolu,  olduğunu biliyorsam orada en az k grubu var.  bu durumda gidiyorum orada olduğunu söylemek için  orada iki farklı grup var.  nasıl karar verdim nasıl işleri kümelemek için en iyisi  birlikte hepsi bu bir gruptaki örnekler  birbirlerine yakın diğer gruptaki örnekler  birbirlerine yakın Onlar oldukça uzaklar.  Bunu yapmanın birçok yolu var.  Sana bir tane göstereceğim.  Bu çok standart bir yol ve Temel olarak, aşağıdaki gibi çalışır.  Tek bildiğim bu ise Orada iki grup var.  Ben başlayacağım sadece seçerek  örnek olarak iki örnek.  Onları rastgele seç.  Aslında rastgele mükemmel değil.  Bende seçmek istemiyorum birbirlerine yakın.  Deneyeceğim ve onları birbirinden ayırın.  Ama iki örnek seçtim Örneklerim olarak.  Ve diğerleri için Eğitim verilerinde örnekler,  Hangisini söylüyorum en yakın mı?  Ne deneyeceğim ve küme oluşturmaktır  özellikli mesafeler  tüm örnekler arasında bu küme küçük.  Ortalama mesafe küçük.  Bakalım yapabilir miyim kümeleri bulmak  ortalama mesafeyi alır Her iki küme için  mümkün olduğunca küçük.  Bu algoritma tarafından çalışır iki örnek seçmek,  diğerlerini kümelemek basitçe söyleyerek örnekler  gruba koymak bu örneğe en yakın olanı.  Bir zamanlar var bu kümeler ben  medyanı bulacak bu grubun elemanı.  Kasten değil ama medyan, ne merkeze en yakın olanı mı?  Ve bunları örnek olarak kabul edin ve işlemi tekrarlayın.  Ve ben de yaparım bazı zamanlar  ya da ben alamadım kadar süreçteki değişim.  Bu yüzden kümeleme mesafeye göre.  Ve biz geri döneceğiz bir saniyedeki mesafe.  Yani burada ne olurdu futbolcularıma sahibim.  Eğer bunu yeni yapsaydım ağırlığına göre,  doğal var Ayırma çizgisi  Ve bir anlam ifade ediyor.  Tamam?  Bu üç belli ki kümelenmiş,  ve yine Sadece bu eksende.  Hepsi buradalar.  Bu yedi farklı bir yer.  Doğal var orada çizgi bölerek.  Tabanlı yaparsam Yükseklikte, temiz değil.  Bu ne benim algoritma geldi  en iyisi ile burada çizgi bölerek,  Yani bu dört, tekrar, sadece bu eksene dayanarak  birbirlerine yakınlar.  Bu altı birbirine yakın.  Ama neredeyse o kadar temiz değil.  Ve bu da bir parçası bakacağımız konu  nasıl bulabilirim en iyi kümeler.  İkisini de kullanırsam boy ve kilo, ben  aslında, öyleydi naziksin, değil mi?  Bu üç küme birlikte. birbirlerine yakınlar  sadece açısından düzlemde mesafe.  Bu yedi kişi birbirine yakın.  Güzel bir doğal var buradan çizgiyi bölerek.  Ve aslında, bu bana bir sınıflandırıcı verir.  Bu çizgi eşit hat  merkezler arasında bu iki kümenin.  Anlamı, herhangi bir nokta bu çizgi boyunca  aynı bu grubun merkezi  Bu gruba olduğu gibi.  Ve böylece yeni bir örnek, çizginin üzerinde ise,  Ben o etiketi alır derdim. çizginin altındaysa,  bu etiketi alır.  Bir saniye sonra bakmak için geri dön  nasıl ölçüyoruz mesafeler  ama buradaki fikir oldukça basit.  Gruplandırma bulmak istiyorum birbirine yakın  ve çok uzak diğer grup.  Diyelim ki aslında biliyordum Bu oyuncuların üzerindeki etiketler.  Bunlar alıcılar.  Bunlar ketenler.  Ve sizin için futbol taraftarları kimlerdir,  Bunu çözebilirsin, değil mi?  Bunlar iki sıkı uç.  Çok daha büyükler.  Bence bu Bennett ve eğer sen gerçekten Gronk  büyük bir Patriots hayranı.  Ama bunlar sıkı biter bunlar geniş alıcılardır,  ve olacak bir saniye sonra gel  ama etiketler var.  Şimdi yapmak istediğim şey söylemek, eğer faydalanabilirsem  etiketleri bilmek, nasıl bu grupları bölebilir miyim?  Ve bu görmek kolay.  Bu konuda temel fikir durum, eğer öyleyse  etiketli gruplar var bu özellikte  boşluk yapmak istediğim şey doğal olarak bir yüzey bul  o boşluğu ayırır.  Şimdi yeraltı süslü bir kelimedir.  Diyor ki iki boyutlu kasa,  bilmek istiyorum en iyi çizgi nedir  tek bir hat bulabilirsem, tüm örnekleri ayıran  hepsinden bir etiket ile ikinci etiket örnekleri.  Bunu göreceğiz, eğer örnekler iyi ayrılmış,  bu kolay yapmak ve bu harika.  Ancak bazı durumlarda, Olacak  daha karmaşık çünkü bazı örnekler  çok yakın olabilir bir başkasına.  Ve bu gidiyor bir problem ortaya çıkarmak  Son dersi gördüğünde.  Fazla giymekten kaçınmak istiyorum.  Oluşturmak istemiyorum gerçekten karmaşık yüzey  şeyleri ayırmak için.  Ve böylece yapmak zorunda kalabiliriz birkaç yanlış tolere etmek  etiketli şeyler, eğer dışarı çıkaramayız.  Ve zaten senin gibi Bu durumda, anladım  etiketli verilerle, en uygun çizgi var  tam orada.  280 poundun üzerindeki herkes Harika bir yan hakem olacak.  280 pound altındaki herkes alıcı olması daha muhtemeldir.  TAMAM.  Bu yüzden iki farklı var düşünmeye çalışmanın yolları  Bu etiketlemeyi yapmak hakkında.  Geri geleceğim ikisi de bir saniye içinde.  Şimdi eklediğimi varsayalım bazı yeni verilerde.  Yeni örnekleri etiketlemek istiyorum.  Şimdi bunlar aslında oyuncu Farklı bir pozisyon  Bunlar geri koşuyorlar.  Ama derim ki, bildiğim kadarıyla alıcılar ve çamaşırlardır.  Bu iki yeni veri noktasını elde ediyorum.  Bilmek isterdim olmaları daha muhtemel  Bir alıcı mı yoksa bir astar mı?  Ve veri var Bu iki bey için.  Yani geri dönersem Şimdi onları çizmek,  oh sorunlardan birini farkettiniz.  Demek benim askerlerim var kırmızı olanlar benim alıcılarım  iki siyah nokta iki çalışan sırt.  Ve tam burada dikkat edin.  Gerçekten olacak bu ikisini ayırmak zor  birbirinden örnekler.  Birbirlerine çok yakınlar.  Ve bu olacak şeylerden biri olmak  takas etmeliyiz.  Ama kullanmayı düşünürsem sınıflandırıcı olarak öğrendiklerimi  etiketlenmemiş veriler ile iki kümem vardı.  Şimdi görüyorsun, oh ilginç bir örnek.  Bu yeni örnek söyle açıkça  yan hakemden daha çok alıcı gibi.  Ama oradaki, belirsiz.  Neredeyse tam olarak yalan bu çizgi boyunca  bu iki küme arasında.  Ben de derdim ki ben kümelemeyi yeniden düşünmek istiyorum  ya da söylemek istiyorum ki ne biliyor musun?  Bildiğim gibi belki orada burada iki küme değil.  Belki üç tane vardır.  Ve sınıflandırmak istiyorum Onları biraz farklı.  Bu yüzden geri döneceğim.  Öte yandan, eğer etiketli verileri kullanmıştı  bölme çizgim vardı.  Bu gerçekten kolay.  İkisinin de yeni örnekler açıkça  Ayırma çizgisinin altında.  Açıkça yapacağım örnekler  varlık olarak sınıflandırmak alıcılar gibi  Keten gibiler.  Ve biliyorum ki bir futbol örneği.  Futbolu sevmiyorsan, başka bir örnek seç.  Ama sen al neden yapabileceğimin anlamı  etiketli verileri kullanmak dava ve etiketlenmemiş dava  farklı gelmek kümeleri oluşturmanın yolları.  Ne gidiyoruz sonraki 2 üzerinden yapmak  ve 1/2 ders nasıl bakalım bakalım  bu şekilde öğrenmek için kod yaz şeyleri ayırmak?  Modelleri öğreneceğiz etiketlenmemiş verilere dayanarak.  Benim yapmadığım durum bu Etiketlerin ne olduğunu bilmek  sadece yollar bulmaya çalışarak işleri bir araya getirmek  yakında ve sonra etiket atamak için kümeler  yeni verilere.  Ve biz modelleri öğreneceğiz etiketli verilere bakarak  ve en iyi nasıl geldiğimizi görmek ayrılmanın bir yolu var  bir çizgi veya bir düzlem veya bir satırların toplanması, örnekler  bir gruptan diğer grubun örnekleri.  Onayı ile abartmadan kaçınmak istiyoruz,  oluşturmak istemiyoruz gerçekten karmaşık bir sistem.  Ve sonuç olarak, gidiyoruz  biraz yapmak zorunda olmak ne arasındaki değiş tokuşlar  yanlış pozitif diyoruz ve yanlış negatifler.  Ancak ortaya çıkan sınıflandırıcı yeni verileri etiketleyebilir  sadece nereye karar vererek saygılısın  Bu ayırma çizgisine.  Demek istediğin işte sonraki 2'yi görmek için  ve 1/2 dersler.  Her makine öğrenmesi yöntemi beş temel bileşene sahiptir.  Neyin olduğuna karar vermeliyiz eğitim verileri  ve nasıl değerlendireceğiz bu sistemin başarısı.  Zaten gördük bunun bazı örnekleri.  Karar vermeliyiz nasıl gidiyoruz  her örneği temsil etmek biz veriyoruz.  Yüksekliği seçtim ve Futbol oyuncuları için ağırlık.  Ama daha iyi olabilirdim ortalama hız seçmek için kapalı  veya bilmiyorum kol uzunluk, başka bir şey.  Neyi nasıl çözebilirim doğru özellikler.  Ve bununla ilişkili mesafeleri nasıl ölçebilirim  bu özellikler arasında?  Ne olduğuna nasıl karar verebilirim yakın ve ne yakın değil?  Belki de farklı olmalı Boy ve boy arasındaki ağırlık terimleri,  Örneğin.  Bu kararı vermem gerekiyor.  Ve bunlar iki şey biziz  size örnekler göstereceğim bugün, nasıl geçileceğini.  Gelecek haftadan itibaren Profesör Guttag  sana nasıl olduğunu gösterecek Bunları al ve gerçekten başla  daha ayrıntılı sürümler oluşturmak kümelemenin ölçülmesi,  bulmak için benzerlikleri ölçmek sizin için nesnel bir işlev  ne olduğuna karar vermek için küçültmek istiyorum kullanılacak en iyi kümedir.  Ve sonra en iyisi nedir istediğiniz optimizasyon yöntemi  Bu modeli öğrenmek için kullanmak.  Öyleyse konuşmaya başlayalım özellikleri hakkında.  Ben bir dizi var etiketli veya etiketsiz örnekler.  Ne olduğuna karar vermem gerek bu örnekler hakkında  ben kullandığımda kullanışlıdır ne olduğuna karar vermek istiyorum  başka bir şeye yakın ya da değil.  Ve sorunlardan biri gerçekten kolay olsaydı  gerçekten kolay olurdu.  Özellikler her zaman ne istersen yakala.  Belabor olacağım o futbol benzetmesi,  ama neden seçtim yükseklik ve ağırlık.  Çünkü bulmak kolaydı.  Bilirsin, eğer çalışırsan New England Patriots, ne  gerçekten olan şey ne zaman sorarsan  doğru özellik nedir?  Muhtemelen başka biri şeylerin birleşimi.  Demek tasarımcı olarak ne demek zorundayım  kullanmak istediğim özellikler.  Bu teklif, tarafından bir şekilde  büyük istatistikçilerden 20. yüzyılın  Bence onu iyi yakalar.  Yani özellik mühendisliği, senin gibi, bir programcı olarak,  karar vermek için geliyor Her ikisi de nelerdir?  Bu vektör içinde ölçmek istiyorum bir araya getireceğim  ve nasıl karar vereceğim kilo için göreceli yollar?  Öyleyse John ve Ana ve ben işimizi yapabilirdi  bu terim gerçekten kolay eğer otursaydık  başında terim ve dedi ki,  bunu öğrettik birçok kez ders.  Biz veri var Bilmiyorum,  John, binlerce öğrenci Muhtemelen bu süre içinde.  Sadece bir inşa edelim küçük öğrenme algoritması  bu veri setini alır ve final notunu tahmin eder.  Zorunda değilsin sınıfa gel  geçmek zorunda bütün problemler,  çünkü biz sadece final notunu tahmin et.  Bu iyi olmaz mıydı?  İşimizi biraz daha kolaylaştırın, ve sen ya da değil  bu fikir gibi.  Ama düşünebilirdim o notu tahmin etmek?  Şimdi neden söylüyorum bu örnek  Ben görmeye çalışıyordum birkaç gülümsemeye kapılabilirdi.  Orada birkaç tane gördüm.  Ancak özellikleri düşünün.  Neyi ölçtüm?  Aslında, bunu giyeceğim John bu onun fikri.  Ne ölçecekti?  Eh, not ortalaması muhtemelen bir performansın kötü tahmincisi.  Başka iyi dersler sen  Bu sınıfta iyi yapması muhtemel.  Bunu kullanacağım biri çok dikkatli.  Önceki programlama deneyimi en azından bir öngörücüdür,  ama bu bir Mükemmel bir tahmin  Olmayanlar önceden programlanmış  Bu sınıfta hala yapabilirsin. Bu sınıfta gerçekten iyi yapın.  Ama bu bir göstergesidir başka programlama gördün  duujjil.  Öte yandan, ben yapmam astrolojiye inan.  Yani ayı sanmıyorum içinde doğduğun  astrolojik işaret doğduğun altında  Muhtemelen yapacak bir şeyi vardır. programın ne kadar iyi.  O göz renginden şüpheliyim yapacak bir şeyi var  programın ne kadar iyi.  Kaptın bu işi.  Bazı özellikler önemli, diğerleri yapmaz.  Şimdi sadece hepsini atabilirim özellikleri ve umuyorum ki  makine öğrenme algoritması istediklerini sıralar  onlardan uzak durmamak için.  Ama sana bunu hatırlatıyorum abartma fikri.  Bunu yaparsam, tehlike var  bazı bulacağını doğum arasındaki ilişki  ay, göz rengi ve not ortalaması.  Ve bu olacak bir karara varmak  Gerçekten sevmediğimizi.  Bu arada, durumda endişelisin  Seni temin ederim o Stu Schmill  dekanında kabul departmanı  makine kullanmaz seni seçmeyi öğreniyorum.  O aslında bir bakar bir sürü şey  çünkü kolay değil onu bir makine ile değiştir.  Henüz.  Tamam.  Peki bu ne diyor düşünmemiz gerek  özellikleri nasıl seçiyoruz.  Ve çoğunlukla, ne yapmaya çalışıyoruz  denilen bir şeyi en üst düzeye çıkarmak sinyal / gürültü oranı.  Bu özellikleri büyüt en fazla bilgiyi taşımak,  ve yapmayanları da kaldırın.  Bu yüzden göstermek istiyorum nasıl bir örnek  bunun hakkında düşünebilirsin.  Sürüngenleri etiketlemek istiyorum.  İle gelmek istiyorum hayvanları etiketleme yolu,  onlar bir sürüngen mi değil mi?  Ve sana tek bir örnek vereyim.  Tek bir örnekle, Gerçekten fazla bir şey yapamazsın.  Ama bu örnekten biliyorum bu bir kobra, yumurtlar  ölçekleri var zehirli, soğuk kanlı  bacakları yok ve bu bir sürüngen.  Böylece modelimi söyleyebilirim bir sürüngen  Emin değilim.  Henüz yeterli veri yok.  Ama sana verirseniz ikinci bir örnek  ve ayrıca olur yumurtlayan olmak,  ölçekleri var, zehirli soğuk kanlı, bacaksız.  İşte benim modelim değil mi?  Mükemmel makul modelini tasarlayıp tasarlamadığımı  veya bir makine öğrenmesi algoritma olur  Bunların hepsi varsa, diyor mu? true, bir sürüngen olarak etiketleyin.  TAMAM?  Ve şimdi sana veriyorum bir boa yılanı.  Ah.  Bu bir sürüngen.  Fakat bu modele uymuyor.  Ve özellikle, Yumurtlama değil,  ve zehirli değil.  Bu yüzden modeli düzeltmeliyim.  Veya algoritması var modeli düzeltmeliyim.  Ve bunu sana hatırlatmak istiyorum. özelliklere bakıyor.  Bu yüzden başladım Beş özellikli.  Bu uygun değil.  Muhtemelen ne ben yapmalı, azaltmak.  Ben ölçeklere bakacağım.  Bakacağım Soğuk kanlı  Bacaklara bakacağım.  Bu hepsini yakalar üç örnek.  Tekrar düşünürsen kümeleme açısından bu,  üçü de buna uygun olurdu.  TAMAM.  Şimdi sana başka bir örnek vereyim.  tavuk.  Bunun bir sürüngen olduğunu sanmıyorum.  Aslında ben güzelim Elbette sürüngen değil.  Ve güzel hala Bu modele uyar, değil mi?  Çünkü terazileri varken, farkına varabilirsin  soğuk kanlı değil ve bacakları var.  Bu yüzden olumsuz bir örnek Bu modeli güçlendirir.  Kulağa iyi geliyor.  Ve şimdi vereceğim sen bir timsahsın  Bu bir sürüngen.  Ve oh şekerleme, değil mi?  Modeli tatmin etmiyor.  Çünkü sahip olduğu sürece ölçekler ve soğuk kanlıdır  bacakları var.  İşim bitmek üzere örnek ile.  Ama sen noktayı görüyorsun.  Tekrar düşünmeliyim Bunu nasıl daraltacağım hakkında.  Ve yapabilirdim tamam diyerek.  Biraz daha yapalım karmaşık, ölçekleri var.  soğuk kanlı, 0 veya dört bacaklı--  Bunun bir sürüngen olduğunu söyleyeceğim.  Sana dart kurbağayı vereceğim.  Sürüngen değil bu bir amfibi.  Ve bu güzel çünkü hala bunu tatmin ediyor.  Yani bu dışarıda bir örnek kümenin  Ölçek yok diyor soğuk kanlı değil  ama dört bacağı olur.  Sürüngen değil.  Bu iyi.  Ve sonra sana--  Sana vermek zorundayım bir piton, değil mi?  Yani, zorunda olmalı Burada bir piton ol.  Ah, hadi ama.  En azından büyüdü bunu söylediğimde ben.  Burada bir piton olmalı.  Ve sana veriyorum Bu ve bir somon.  Ve şimdi başım belada.  Çünkü ölçeklere bak, bak soğuk kanlı bacaklara bak.  Onları ayıramıyorum.  Bu özelliklerde hayatta olmaz  bir yolla gelmek bu doğru olacak  pitonun bir olduğunu söyle sürüngen ve somon değil.  Ve böylece kolay değil bu kurala eklemenin bir yolu.  Ve muhtemelen elimden gelenin en iyisini şey basitçe geri dönmek  sadece iki özelliğe, ölçekler ve soğuk kanlı.  Ve temelde eğer bir şey varsa  ölçekler ve soğuk kanlı Ben buna sürüngen diyeceğim.  Eğer yoksa ikisi de  Söyleyeceğim bu bir sürüngen değil.  Mükemmel olmayacak.  Yanlış gidiyor somonu etiketleyin.  Ama ben bir tasarım yaptım seçim burada önemli.  Ve tasarım seçimi şudur Yanlış negatifler almayacağım.  Bunun anlamı gitmiyor  herhangi bir şeyin örneği olmak bu benim sürüngen değilim  bir sürüngen arayacak.  Bazı yanlış pozitifler olabilir.  Bu yüzden yanlış yoldan yaptım.  Yanlış bir negatif her şeyi söylüyor  bu sürüngen değilim, gidiyorum bu yönü kategorize etmek.  Bazı yanlış olabilir Bu pozitif,  Birkaç şey olabilir yanlış yapacağım  bir sürüngen olarak etiketleyin.  Ve özellikle, somon gidiyor  Bunun bir örneği olmak için.  Bu sahte takas pozitifler ve yanlış negatifler  is something that we worry about, as we think about it.  Because there's no perfect way, in many cases,  to separate out the data.  And if you think back to my example of the New England  Patriots, that running back and that wide receiver were  so close together in height and weight,  there was no way I'm going to be able to separate them apart.  And I just have to be willing to decide  how many false positives or false negatives  do I want to tolerate.  Once I've figured out what features to use, which is good,  then I have to decide about distance.  How do I compare two feature vectors?  I'm going to say vector because there could  be multiple dimensions to it.  How do I decide how to compare them?  Because I want to use the distances to figure out either  how to group things together or how to find a dividing line  that separates things apart.  So one of the things I have to decide is which features.  I also have to decide the distance.  And finally, I may want to decide  how to weigh relative importance of different dimensions  in the feature vector.  Some may be more valuable than others in making that decision.  And I want to show you an example of that.  So let's go back to my animals.  I started off with a feature vector that actually  had five dimensions to it.  It was egg-laying, cold blooded, has scales,  I forget what the other one was, and number of legs.  So one of the ways I could think about this  is saying I've got four binary features and one integer  feature associated with each animal.  And one way to learn to separate out reptiles from non reptiles  is to measure the distance between pairs of examples  and use that distance to decide what's near each other  and what's not.  And as we've said before, it will either  be used to cluster things or to find a classifier surface that  separates them.  So here's a simple way to do it.  For each of these examples, I'm going to just let true  be 1, false be 0.  So the first four are either 0s or 1s.  And the last one is the number of legs.  And now I could say, all right.  How do I measure distances between animals  or anything else, but these kinds of feature vectors?  Here, we're going to use something  called the Minkowski Metric or the Minkowski difference.  Given two vectors and a power, p,  we basically take the absolute value  of the difference between each of the components  of the vector, raise it to the p-th power, take the sum,  and take the p-th route of that.  So let's do the two obvious examples.  If p is equal to 1, I just measure the absolute distance  between each component, add them up, and that's my distance.  It's called the Manhattan metric.  The one you've seen more, the one we saw last time,  if p is equal to 2, this is Euclidean distance, right?  It's the sum of the squares of the differences  of the components.  Take the square root.  Take the square root because it makes  it have certain properties of a distance.  That's the Euclidean distance.  So now if I want to measure difference between these two,  here's the question.  Is this circle closer to the star or closer to the cross?  Unfortunately, I put the answer up here.  But it differs, depending on the metric I use.  Right?  Euclidean distance, well, that's square root of 2 times 2,  so it's about 2.8.  And that's three.  So in terms of just standard distance in the plane,  we would say that these two are closer than those two are.  Manhattan distance, why is it called that?  Because you can only walk along the avenues and the streets.  Manhattan distance would basically  say this is one, two, three, four units away.  This is one, two, three units away.  And under Manhattan distance, this is closer,  this pairing is closer than that pairing is.  Now you're used to thinking Euclidean.  We're going to use that.  But this is going to be important  when we think about how are we comparing distances  between these different pieces.  So typically, we'll use Euclidean.  We're going to see Manhattan actually has some value.  So if I go back to my three examples-- boy, that's  a gross slide, isn't it?  But there we go--  rattlesnake, boa constrictor, and dart frog.  There is the representation.  I can ask, what's the distance between them?  In the handout for today, we've given you a little piece  of code that would do that.  And if I actually run through it, I get,  actually, a nice little result. Here  are the distances between those vectors using Euclidean metric.  I'm going to come back to them.  But you can see the two snakes, nicely, are  reasonably close to each other.  Whereas, the dart frog is a fair distance away from that.  Güzel değil mi?  That's a nice separation that says there's  a difference between these two.  OK.  Now I throw in the alligator.  Sounds like a Dungeons &amp; Dragons game.  I throw in the alligator, and I want to do the same comparison.  And I don't get nearly as nice a result. Because now it says,  as before, the two snakes are close to each other.  But it says that the dart frog and the alligator  are much closer, under this measurement,  than either of them is to the other.  And to remind you, right, the alligator and the two  snakes I would like to be close to one another and a distance  away from the frog.  Because I'm trying to classify reptiles versus not.  So what happened here?  Well, this is a place where the feature engineering  is going to be important.  Because in fact, the alligator differs from the frog  in three features.  And only in two features from, say, the boa constrictor.  But one of those features is the number of legs.  And there, while on the binary axes,  the difference is between a 0 and 1,  here it can be between 0 and 4.  So that is weighing the distance a lot more than we would like.  The legs dimension is too large, if you like.  How would I fix this?  This is actually, I would argue, a natural place  to use Manhattan distance.  Why should I think that the difference  in the number of legs or the number of legs difference  is more important than whether it has scales or not?  Why should I think that measuring that distance  Euclidean-wise makes sense?  They are really completely different measurements.  And in fact, I'm not going to do it,  but if I ran Manhattan metric on this,  it would get the alligator much closer to the snakes,  exactly because it differs only in two features, not three.  The other way I could fix it would  be to say I'm letting too much weight be associated  with the difference in the number of legs.  So let's just make it a binary feature.  Either it doesn't have legs or it does have legs.  Run the same classification.  And now you see the snakes and the alligator  are all close to each other.  Whereas the dart frog, not as far away as it was before,  but there's a pretty natural separation, especially  using that number between them.  What's my point?  Choice of features matters.  Throwing too many features in may, in fact,  give us some overfitting.  And in particular, deciding the weights  that I want on those features has a real impact.  And you, as a designer or a programmer,  have a lot of influence in how you think about using those.  So feature engineering really matters.  How you pick the features, what you use  is going to be important.  OK.  The last piece of this then is we're  going to look at some examples where we give you data, got  features associated with them.  We're going to, in some cases have them labeled,  in other cases not.  And we know how now to think about how do we  measure distances between them.  John.  JOHN GUTTAG: You probably didn't intend  to say weights of features.  You intended to say how they're scaled.  ERIC GRIMSON: Sorry.  The scales and not the-- thank you, John.  No, I did.  I take that back.  I did not mean to say weights of features.  I meant to say the scale of the dimension  is going to be important here.  Thank you, for the amplification and correction.  You're absolutely right.  JOHN GUTTAG: Weights, we use in a different way,  as we'll see next time.  ERIC GRIMSON: And we're going to see  next time why we're going to use weights in different ways.  So rephrase it.  Block that out of your mind.  We're going to talk about scales and the scale on the axes  as being important here.  And we already said we're going to look  at two different kinds of learning,  labeled and unlabeled, clustering and classifying.  And I want to just finish up by showing you  two examples of that.  How we would think about them algorithmically,  and we'll look at them in more detail next time.  As we look at it, I want to remind  you the things that are going to be important to you.  How do I measure distance between examples?  What's the right way to design that?  What is the right set of features to use in that vector?  And then, what constraints do I want to put on the model?  In the case of unlabelled data, how  do I decide how many clusters I want to have?  Because I can give you a really easy way to do clustering.  If I give you 100 examples, I say build 100 clusters.  Every example is its own cluster.  Distance is really good.  It's really close to itself, but it does a lousy job  of labeling things on it.  So I have to think about, how do I  decide how many clusters, what's the complexity  of that separating service?  How do I basically avoid the overfitting problem,  which I don't want to have?  So just to remind you, we've already  seen a little version of this, the clustering method.  This is a standard way to do it, simply repeating what  we had on an earlier slide.  If I want to cluster it into groups,  I start by saying how many clusters am I looking for?  Pick an example I take as my early representation.  For every other example in the training data,  put it to the closest cluster.  Once I've got those, find the median, repeat the process.  And that led to that separation.  Now once I've got it, I like to validate it.  And in fact, I should have said this better.  Those two clusters came without looking at the two black dots.  Once I put the black dots in, I'd  like to validate, how well does this really work?  And that example there is really not very encouraging.  It's too close.  So that's a natural place to say, OK, what if I did this  with three clusters?  That's what I get.  I like the that.  Tamam?  That has a really nice cluster up here.  The fact that the algorithm didn't know the labeling  is irrelevant.  There's a nice grouping of five.  There's a nice grouping of four.  And there's a nice grouping of three in between.  And in fact, if I looked at the average distance  between examples in each of these clusters,  it is much tighter than in that example.  And so that leads to, then, the question of should I  look for four clusters?  Question, please.  AUDIENCE: Is that overlap between the two clusters  not an issue?  ERIC GRIMSON: Yes.  The question is, is the overlap between the two clusters  a problem?  Yok hayır.  I just drew it here so I could let  you see where those pieces are.  But in fact, if you like, the center is there.  Those three points are all closer to that center  than they are to that center.  So the fact that they overlap is a good question.  It's just the way I happened to draw them.  I should really draw these, not as  circles, but as some little bit more convoluted surface.  OK?  Having done three, I could say should I look for four?  Well, those points down there, as I've already said,  are an example where it's going to be  hard to separate them out.  And I don't want to overfit.  Because the only way to separate those out  is going to be to come up with a really convoluted cluster,  which I don't like.  Tamam?  Let me finish with showing you one other example  from the other direction.  Which is, suppose I give you labeled examples.  So again, the goal is I've got features  associated with each example.  They're going to have multiple dimensions on it.  But I also know the label associated with them.  And I want to learn what is the best  way to come up with a rule that will let me take new examples  and assign them to the right group.  A number of ways to do this.  You can simply say I'm looking for the simplest surface that  will separate those examples.  In my football case that were in the plane, what's  the best line that separates them,  which turns out to be easy.  I might look for a more complicated surface.  And we're going to see an example in a second  where maybe it's a sequence of line segments  that separates them out.  Because there's not just one line that does the separation.  As before, I want to be careful.  If I make it too complicated, I may  get a really good separator, but I overfit to the data.  And you're going to see next time.  I'm going to just highlight it here.  There's a third way, which will lead  to almost the same kind of result  called k nearest neighbors.  And the idea here is I've got a set of labeled data.  And what I'm going to do is, for every new example,  say find the k, say the five closest labeled examples.  And take a vote.  If 3 out of 5 or 4 out of 5 or 5 out of 5 of those labels  are the same, I'm going to say it's part of that group.  And if I have less than that, I'm  going to leave it as unclassified.  And that's a nice way of actually thinking  about how to learn them.  And let me just finish by showing you an example.  Now I won't use football players on this one.  I'll use a different example.  I'm going to give you some voting data.  I think this is actually simulated data.  But these are a set of voters in the United States  with their preference.  They tend to vote Republican.  They tend to vote Democrat.  And the two categories are their age and how far away  they live from Boston.  Whether those are relevant or not, I don't know,  but they are just two things I'm going to use to classify them.  And I'd like to say, how would I fit a curve  to separate those two classes?  I'm going to keep half the data to test.  I'm going to use half the data to train.  So if this is my training data, I  can say what's the best line that separates these?  I don't know about best, but here are two examples.  This solid line has the property that all the Democrats  are on one side.  Everything on the other side is a Republican,  but there are some Republicans on this side of the line.  I can't find a line that completely separates these,  as I did with the football players.  But there is a decent line to separate them.  Here's another candidate.  That dash line has the property that on the right side  you've got-- boy, I don't think this is deliberate,  John, right-- but on the right side,  you've got almost all Republicans.  It seems perfectly appropriate.  One Democrat, but there's a pretty good separation there.  And on the left side, you've got a mix of things.  But most of the Democrats are on the left side of that line.  Tamam?  The fact that left and right correlates  with distance from Boston is completely irrelevant here.  But it has a nice punch to it.  JOHN GUTTAG: Relevant, but not accidental.  ERIC GRIMSON: But not accidental.  Teşekkür ederim.  Tamam.  So now the question is, how would I evaluate these?  How do I decide which one is better?  And I'm simply going to show you,  very quickly, some examples.  First one is to look at what's called the confusion matrix.  What does that mean?  It says for this, one of these classifiers for example,  the solid line.  Here are the predictions, based on the solid line  of whether they would be more likely to be  Democrat or Republican.  And here is the actual label.  Same thing for the dashed line.  And that diagonal is important because those are  the correctly labeled results.  Right?  It correctly, in the solid line case,  gets all of the correct labelings of the Democrats.  It gets half of the Republicans right.  But it has some where it's actually Republican,  but it labels it as a Democrat.  That, we'd like to be really large.  And in fact, it leads to a natural measure  called the accuracy.  Which is, just to go back to that,  we say that these are true positives.  Meaning, I labeled it as being an instance, and it really is.  These are true negatives.  I label it as not being an instance, and it really isn't.  And then these are the false positives.  I labeled it as being an instance and it's not,  and these are the false negatives.  I labeled it as not being an instance, and it is.  And an easy way to measure it is to look at the correct labels  over all of the labels.  The true positives and the true negatives,  the ones I got right.  And in that case, both models come up with a value of 0.7.  So which one is better?  Well, I should validate that.  And I'm going to do that in a second  by looking at other data.  We could also ask, could we find something  with less training error?  This is only getting 70% right.  Not great.  Well, here is a more complicated model.  And this is where you start getting  worried about overfitting.  Now what I've done, is I've come up  with a sequence of lines that separate them.  So everything above this line, I'm going to say  is a Republican.  Everything below this line, I'm going to say is a Democrat.  So I'm avoiding that one.  I'm avoiding that one.  I'm still capturing many of the same things.  And in this case, I get 12 true positives, 13 true negatives,  and only 5 false positives.  And that's kind of nice.  You can see the 5.  It's those five red ones down there.  It's accuracy is 0.833.  And now, if I apply that to the test data, I get an OK result.  It has an accuracy of about 0.6.  I could use this idea to try and generalize to say could I  come up with a better model.  And you're going to see that next time.  There could be other ways in which I measure this.  And I want to use this as the last example.  Another good measure we use is called PPV, Positive Predictive  Value which is how many true positives do I come up with out  of all the things I labeled positively.  And in this solid model, in the dashed line,  I can get values about 0.57.  The complex model on the training data is better.  And then the testing data is even stronger.  And finally, two other examples are called  sensitivity and specificity.  Sensitivity basically tells you what percentage  did I correctly find.  And specificity said what percentage  did I correctly reject.  And I show you this because this is  where the trade-off comes in.  If sensitivity is how many did I correctly  label out of those that I both correctly  labeled and incorrectly labeled as being negative,  how many them did I correctly label  as being the kind that I want?  I can make sensitivity 1.  Label everything is the thing I'm looking for.  Great.  Everything is correct.  But the specificity will be 0.  Because I'll have a bunch of things incorrectly labeled.  I could make the specificity 1, reject everything.  Say nothing as an instance.  True negatives goes to 1, and I'm in a great place there,  but my sensitivity goes to 0.  I've got a trade-off.  As I think about the machine learning algorithm I'm using  and my choice of that classifier,  I'm going to see a trade off where  I can increase specificity at the cost of sensitivity or vice  versa.  And you'll see a nice technique called ROC or Receiver Operator  Curve that gives you a sense of how you want to deal with that.  And with that, we'll see you next time.  We'll take your question off line  if you don't mind, because I've run over time.  But we'll see you next time where Professor Guttag  will show you examples of this. 